{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1、tensorflow 1.x 保存 MNIST 分类模型\n",
    "\n",
    "本文档在 tensorflow 1.x 的环境下训练一个mnist数据集分类模型，并保存训练之后的模型，作为后续部署的模型，说明如下：  \n",
    "\n",
    "**（1）**由于本项目主要是为了说明部署方法，所以这里采用简单的模型结果，复杂的模型在保存和部署上并没有什么区别  \n",
    "**（2）**模型保存成 .pb　的格式，.pb模型通用性比较好，可以实现不同平台（serving、java、andriod等），具体参考[TensorFlow 保存模型为 PB 文件](https://zhuanlan.zhihu.com/p/32887066)  \n",
    "\n",
    "tensorflow 中保存为 .pb 格式模型的方法有两种：  \n",
    "**（1）** 保存为单个文件  \n",
    "**（2）** 保存为文件夹  \n",
    "\n",
    "下面分别说明保存方法和调用方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 1.1 第一种保存方法——保存为单个 .pb 文件\n",
    "##### **1.1.1 模型训练和保存**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-1716b1a1ccb1>:6: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/liuzard/miniconda3/envs/tf_113/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/liuzard/miniconda3/envs/tf_113/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/liuzard/miniconda3/envs/tf_113/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/liuzard/miniconda3/envs/tf_113/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/liuzard/miniconda3/envs/tf_113/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From <ipython-input-1-1716b1a1ccb1>:22: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /home/liuzard/miniconda3/envs/tf_113/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "after 0 training steps, loss of train set is 2.414426,validation accuracy is 0.355400\n",
      "after 1000 training steps, loss of train set is 0.192877,validation accuracy is 0.970600\n",
      "after 2000 training steps, loss of train set is 0.101779,validation accuracy is 0.976200\n",
      "after 3000 training steps, loss of train set is 0.011525,validation accuracy is 0.980800\n",
      "after 4000 training steps, loss of train set is 0.018916,validation accuracy is 0.979600\n",
      "after 5000 training steps, loss of train set is 0.019501,validation accuracy is 0.981000\n",
      "after 6000 training steps, loss of train set is 0.010958,validation accuracy is 0.981000\n",
      "after 7000 training steps, loss of train set is 0.012181,validation accuracy is 0.982800\n",
      "after 8000 training steps, loss of train set is 0.002947,validation accuracy is 0.981800\n",
      "after 9000 training steps, loss of train set is 0.006591,validation accuracy is 0.981800\n",
      "test accuracy is 0.982000\n",
      "WARNING:tensorflow:From <ipython-input-1-1716b1a1ccb1>:54: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.graph_util.convert_variables_to_constants\n",
      "WARNING:tensorflow:From /home/liuzard/miniconda3/envs/tf_113/lib/python3.6/site-packages/tensorflow/python/framework/graph_util_impl.py:245: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.graph_util.extract_sub_graph\n",
      "INFO:tensorflow:Froze 4 variables.\n",
      "INFO:tensorflow:Converted 4 variables to const ops.\n",
      "WARNING:tensorflow:From <ipython-input-1-1716b1a1ccb1>:56: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import graph_util # 保存模型用到的方法\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# 获取 mnist数据\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\",one_hot=True)\n",
    "mnist_train,mnist_validation,mnist_test=mnist.train,mnist.validation,mnist.test\n",
    "\n",
    "# 模型参数\n",
    "input_dim=784\n",
    "hidden_dim=200\n",
    "output_dim=10\n",
    "learning_rate=0.5\n",
    "train_steps=10000\n",
    "batch_size=100\n",
    "\n",
    "# 模型的输入，在调用部署后的模型时需要用到，所以这里最好自己命名\n",
    "x = tf.placeholder(tf.float32, [None, input_dim], name='x-input')\n",
    "y_ = tf.placeholder(tf.float32, [None, output_dim], name='y-input')\n",
    "\n",
    "# 构建一个三层的全连接层网络，输入层、隐层和输出层分别为784,200,10\n",
    "hidden = tf.layers.dense(inputs=x, units=hidden_dim, activation=tf.nn.relu)\n",
    "y=tf.layers.dense(inputs=hidden,units=output_dim)\n",
    "\n",
    "# 模型的预测输出，注意，因为我们部署之后希望拿到这个值，所以这里最好自己命名，后面部署之后的调用会用到\n",
    "y_pred=tf.math.argmax(y,1,name=\"predict\") \n",
    "\n",
    "# 模型损失\n",
    "cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y, labels=tf.argmax(y_, 1))\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "# 预测精度\n",
    "correct_predict=tf.equal(tf.math.argmax(y,1),tf.math.argmax(y_,1))\n",
    "accuracy=tf.reduce_mean(tf.cast(correct_predict,tf.float32))\n",
    "\n",
    "#模型训练\n",
    "train_step=tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    validation_feed={x:mnist_validation.images,y_:mnist_validation.labels}\n",
    "    test_feed={x:mnist_test.images,y_:mnist_test.labels}\n",
    "    for i in range(train_steps):\n",
    "        train_samples,train_labels=mnist_train.next_batch(batch_size)\n",
    "        _,train_loss=sess.run([train_step,loss],feed_dict={x:train_samples,y_:train_labels})\n",
    "        if i%1000==0:\n",
    "            val_acc=sess.run(accuracy,feed_dict=validation_feed)\n",
    "            print(\"after %d training steps, loss of train set is %f,validation accuracy is %f\"%(i,train_loss,val_acc))\n",
    "    test_acc=sess.run(accuracy,feed_dict=test_feed)\n",
    "    print(\"test accuracy is %f\"%test_acc)\n",
    "    \n",
    "    # 保存模型\n",
    "    # 将权重和偏置等变量转换为常量，然后将计算图保存，可以大大减小保存后的模型\n",
    "    constant_graph = graph_util.convert_variables_to_constants(sess, sess.graph_def,output_node_names=[\"predict\"]) \n",
    "    model_save_path=\"model_save/method_1/mnist_classification.pb\"\n",
    "    with tf.gfile.FastGFile(model_save_path, mode='wb') as f:\n",
    "        f.write(constant_graph.SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### **1.1.2 模型的调用** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 在python 中调用保存好的模型进行预测\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.platform import gfile\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# 获取 mnist数据\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\",one_hot=True)\n",
    "mnist_train,mnist_validation,mnist_test=mnist.train,mnist.validation,mnist.test\n",
    "\n",
    "\n",
    "model_save_path=\"model_save/method_1/mnist_classification.pb\"\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # 读取保存的模型\n",
    "    with gfile.FastGFile(model_save_path, 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "    tf.import_graph_def(graph_def,name='') # 这里的 name 不设置的话，系统默认为 import,则后面 get_tensor_by_name 需要在名称之前加import，如 \"import/predict:0\" \n",
    "    for i,n in enumerate(graph_def.node): # 假如不知道各层的名称，通过打印获取\n",
    "        print(\"\\tName of the node - %s\"%n.name)\n",
    "    g = tf.get_default_graph()\n",
    "    y_pred=g.get_tensor_by_name(\"predict:0\")\n",
    "    x = g.get_tensor_by_name(\"x-input:0\")\n",
    "    y_= sess.run(y_pred, feed_dict={x: mnist_test.images})\n",
    "    print(mnist_test.labels)\n",
    "    print(y_)\n",
    "\n",
    "# 假如报 Attempting to use uninitialized value 的错误，是因为训练的session 影响了这里的session，\n",
    "# 重启一下 kernel,然后再跑这个调用部分即可"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.2 第2种保存方法——保存为文件夹\n",
    "##### **1.2.1 模型训练和保存**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# 获取 mnist数据\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\",one_hot=True)\n",
    "mnist_train,mnist_validation,mnist_test=mnist.train,mnist.validation,mnist.test\n",
    "\n",
    "# 模型参数\n",
    "input_dim=784\n",
    "hidden_dim=200\n",
    "output_dim=10\n",
    "learning_rate=0.5\n",
    "train_steps=10000\n",
    "batch_size=100\n",
    "\n",
    "# 模型的输入，在调用部署后的模型时需要用到，所以这里最好自己命名\n",
    "x = tf.placeholder(tf.float32, [None, input_dim], name='x-input')\n",
    "y_ = tf.placeholder(tf.float32, [None, output_dim], name='y-input')\n",
    "\n",
    "# 构建一个三层的全连接层网络，输入层、隐层和输出层分别为784,200,10\n",
    "hidden = tf.layers.dense(inputs=x, units=hidden_dim, activation=tf.nn.relu)\n",
    "y=tf.layers.dense(inputs=hidden,units=output_dim)\n",
    "\n",
    "# 模型的预测输出，注意，因为我们部署之后希望拿到这个值，所以这里最好自己命名，后面部署之后的调用会用到\n",
    "y_pred=tf.math.argmax(y,1,name=\"predict\") \n",
    "\n",
    "# 模型损失\n",
    "cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y, labels=tf.argmax(y_, 1))\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "# 预测精度\n",
    "correct_predict=tf.equal(tf.math.argmax(y,1),tf.math.argmax(y_,1))\n",
    "accuracy=tf.reduce_mean(tf.cast(correct_predict,tf.float32))\n",
    "\n",
    "#模型训练\n",
    "train_step=tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    validation_feed={x:mnist_validation.images,y_:mnist_validation.labels}\n",
    "    test_feed={x:mnist_test.images,y_:mnist_test.labels}\n",
    "    for i in range(train_steps):\n",
    "        train_samples,train_labels=mnist_train.next_batch(batch_size)\n",
    "        _,train_loss=sess.run([train_step,loss],feed_dict={x:train_samples,y_:train_labels})\n",
    "        if i%1000==0:\n",
    "            val_acc=sess.run(accuracy,feed_dict=validation_feed)\n",
    "            print(\"after %d training steps, loss of train set is %f,validation accuracy is %f\"%(i,train_loss,val_acc))\n",
    "    test_acc=sess.run(accuracy,feed_dict=test_feed)\n",
    "    print(\"test accuracy is %f\"%test_acc)\n",
    "    \n",
    "    # 保存模型\n",
    "    builder = tf.saved_model.builder.SavedModelBuilder('model_save/method_2/')\n",
    "    # SavedModelBuilder里面放的是你想要保存的路径，比如我的路径是根目录下的dense_model文件\n",
    "    builder.add_meta_graph_and_variables(sess, [\"serve\"])\n",
    "    # 第二步必需要有，它是给你的模型贴上一个标签，这样再次调用的时候就可以根据标签来找。我给它起的标签名是\"serve\"，你也可以起别的名字，不过你需要记住你起的名字是什么。\n",
    "    builder.save()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### **1.2.2 模型的调用**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with tf.Session(graph=tf.Graph()) as sess:\n",
    "    tf.saved_model.loader.load(sess, ['serve'], 'model_save/method_2')\n",
    "    y_pred=sess.graph.get_tensor_by_name(\"predict:0\")\n",
    "    x = sess.graph.get_tensor_by_name(\"x-input:0\")\n",
    "    y_= sess.run(y_pred, feed_dict={x: mnist_test.images})\n",
    "    print(mnist_test.labels)\n",
    "    print(y_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with tf.Session(graph=tf.Graph()) as sess:\n",
    "    tf.saved_model.loader.load(sess, ['serve'], 'model_save/method_2')\n",
    "    y_pred=sess.graph.get_tensor_by_name(\"predict:0\")\n",
    "    x = sess.graph.get_tensor_by_name(\"x-input:0\")\n",
    "    y_= sess.run(y_pred, feed_dict={x: mnist_test.images})\n",
    "    print(mnist_test.labels)\n",
    "    print(y_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.2 第2种保存方法——保存为文件夹\n",
    "##### **1.2.1 模型训练和保存**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# 获取 mnist数据\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\",one_hot=True)\n",
    "mnist_train,mnist_validation,mnist_test=mnist.train,mnist.validation,mnist.test\n",
    "\n",
    "# 模型参数\n",
    "input_dim=784\n",
    "hidden_dim=200\n",
    "output_dim=10\n",
    "learning_rate=0.5\n",
    "train_steps=10000\n",
    "batch_size=100\n",
    "\n",
    "# 模型的输入，在调用部署后的模型时需要用到，所以这里最好自己命名\n",
    "x = tf.placeholder(tf.float32, [None, input_dim], name='x-input')\n",
    "y_ = tf.placeholder(tf.float32, [None, output_dim], name='y-input')\n",
    "\n",
    "# 构建一个三层的全连接层网络，输入层、隐层和输出层分别为784,200,10\n",
    "hidden = tf.layers.dense(inputs=x, units=hidden_dim, activation=tf.nn.relu)\n",
    "y=tf.layers.dense(inputs=hidden,units=output_dim)\n",
    "\n",
    "# 模型的预测输出，注意，因为我们部署之后希望拿到这个值，所以这里最好自己命名，后面部署之后的调用会用到\n",
    "y_pred=tf.math.argmax(y,1,name=\"predict\") \n",
    "\n",
    "# 模型损失\n",
    "cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y, labels=tf.argmax(y_, 1))\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "# 预测精度\n",
    "correct_predict=tf.equal(tf.math.argmax(y,1),tf.math.argmax(y_,1))\n",
    "accuracy=tf.reduce_mean(tf.cast(correct_predict,tf.float32))\n",
    "\n",
    "#模型训练\n",
    "train_step=tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    validation_feed={x:mnist_validation.images,y_:mnist_validation.labels}\n",
    "    test_feed={x:mnist_test.images,y_:mnist_test.labels}\n",
    "    for i in range(train_steps):\n",
    "        train_samples,train_labels=mnist_train.next_batch(batch_size)\n",
    "        _,train_loss=sess.run([train_step,loss],feed_dict={x:train_samples,y_:train_labels})\n",
    "        if i%1000==0:\n",
    "            val_acc=sess.run(accuracy,feed_dict=validation_feed)\n",
    "            print(\"after %d training steps, loss of train set is %f,validation accuracy is %f\"%(i,train_loss,val_acc))\n",
    "    test_acc=sess.run(accuracy,feed_dict=test_feed)\n",
    "    print(\"test accuracy is %f\"%test_acc)\n",
    "    \n",
    "    # 保存模型\n",
    "    builder = tf.saved_model.builder.SavedModelBuilder('model_save/method_2/')\n",
    "    # SavedModelBuilder里面放的是你想要保存的路径，比如我的路径是根目录下的dense_model文件\n",
    "    builder.add_meta_graph_and_variables(sess, [\"serve\"])\n",
    "    # 第二步必需要有，它是给你的模型贴上一个标签，这样再次调用的时候就可以根据标签来找。我给它起的标签名是\"serve\"，你也可以起别的名字，不过你需要记住你起的名字是什么。\n",
    "    builder.save()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### **1.2.2 模型的调用**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with tf.Session(graph=tf.Graph()) as sess:\n",
    "    tf.saved_model.loader.load(sess, ['serve'], 'model_save/method_2')\n",
    "    y_pred=sess.graph.get_tensor_by_name(\"predict:0\")\n",
    "    x = sess.graph.get_tensor_by_name(\"x-input:0\")\n",
    "    y_= sess.run(y_pred, feed_dict={x: mnist_test.images})\n",
    "    print(mnist_test.labels)\n",
    "    print(y_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "\tName of the node - x-input\n",
      "\tName of the node - dense/kernel\n",
      "\tName of the node - dense/kernel/read\n",
      "\tName of the node - dense/bias\n",
      "\tName of the node - dense/bias/read\n",
      "\tName of the node - dense/MatMul\n",
      "\tName of the node - dense/BiasAdd\n",
      "\tName of the node - dense/Relu\n",
      "\tName of the node - dense_1/kernel\n",
      "\tName of the node - dense_1/kernel/read\n",
      "\tName of the node - dense_1/bias\n",
      "\tName of the node - dense_1/bias/read\n",
      "\tName of the node - dense_1/MatMul\n",
      "\tName of the node - dense_1/BiasAdd\n",
      "\tName of the node - predict/dimension\n",
      "\tName of the node - predict\n",
      "[[0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[7 2 1 ... 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=tf.Graph()) as sess:\n",
    "    tf.saved_model.loader.load(sess, ['serve'], 'model_save/method_2')\n",
    "    y_pred=sess.graph.get_tensor_by_name(\"predict:0\")\n",
    "    x = sess.graph.get_tensor_by_name(\"x-input:0\")\n",
    "    y_= sess.run(y_pred, feed_dict={x: mnist_test.images})\n",
    "    print(mnist_test.labels)\n",
    "    print(y_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 第2种保存方法——保存为文件夹\n",
    "##### **1.2.1 模型训练和保存**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "after 0 training steps, loss of train set is 2.387276,validation accuracy is 0.381400\n",
      "after 1000 training steps, loss of train set is 0.130141,validation accuracy is 0.969600\n",
      "after 2000 training steps, loss of train set is 0.059555,validation accuracy is 0.973400\n",
      "after 3000 training steps, loss of train set is 0.003633,validation accuracy is 0.980400\n",
      "after 4000 training steps, loss of train set is 0.017264,validation accuracy is 0.981200\n",
      "after 5000 training steps, loss of train set is 0.018133,validation accuracy is 0.980400\n",
      "after 6000 training steps, loss of train set is 0.008507,validation accuracy is 0.983200\n",
      "after 7000 training steps, loss of train set is 0.006637,validation accuracy is 0.982600\n",
      "after 8000 training steps, loss of train set is 0.005118,validation accuracy is 0.983200\n",
      "after 9000 training steps, loss of train set is 0.002663,validation accuracy is 0.983000\n",
      "test accuracy is 0.982400\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: model_save/method_2/saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# 获取 mnist数据\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\",one_hot=True)\n",
    "mnist_train,mnist_validation,mnist_test=mnist.train,mnist.validation,mnist.test\n",
    "\n",
    "# 模型参数\n",
    "input_dim=784\n",
    "hidden_dim=200\n",
    "output_dim=10\n",
    "learning_rate=0.5\n",
    "train_steps=10000\n",
    "batch_size=100\n",
    "\n",
    "# 模型的输入，在调用部署后的模型时需要用到，所以这里最好自己命名\n",
    "x = tf.placeholder(tf.float32, [None, input_dim], name='x-input')\n",
    "y_ = tf.placeholder(tf.float32, [None, output_dim], name='y-input')\n",
    "\n",
    "# 构建一个三层的全连接层网络，输入层、隐层和输出层分别为784,200,10\n",
    "hidden = tf.layers.dense(inputs=x, units=hidden_dim, activation=tf.nn.relu)\n",
    "y=tf.layers.dense(inputs=hidden,units=output_dim)\n",
    "\n",
    "# 模型的预测输出，注意，因为我们部署之后希望拿到这个值，所以这里最好自己命名，后面部署之后的调用会用到\n",
    "y_pred=tf.math.argmax(y,1,name=\"predict\") \n",
    "\n",
    "# 模型损失\n",
    "cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y, labels=tf.argmax(y_, 1))\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "# 预测精度\n",
    "correct_predict=tf.equal(tf.math.argmax(y,1),tf.math.argmax(y_,1))\n",
    "accuracy=tf.reduce_mean(tf.cast(correct_predict,tf.float32))\n",
    "\n",
    "#模型训练\n",
    "train_step=tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    validation_feed={x:mnist_validation.images,y_:mnist_validation.labels}\n",
    "    test_feed={x:mnist_test.images,y_:mnist_test.labels}\n",
    "    for i in range(train_steps):\n",
    "        train_samples,train_labels=mnist_train.next_batch(batch_size)\n",
    "        _,train_loss=sess.run([train_step,loss],feed_dict={x:train_samples,y_:train_labels})\n",
    "        if i%1000==0:\n",
    "            val_acc=sess.run(accuracy,feed_dict=validation_feed)\n",
    "            print(\"after %d training steps, loss of train set is %f,validation accuracy is %f\"%(i,train_loss,val_acc))\n",
    "    test_acc=sess.run(accuracy,feed_dict=test_feed)\n",
    "    print(\"test accuracy is %f\"%test_acc)\n",
    "    \n",
    "    # 保存模型\n",
    "    builder = tf.saved_model.builder.SavedModelBuilder('model_save/method_2/')\n",
    "    # SavedModelBuilder里面放的是你想要保存的路径，比如我的路径是根目录下的dense_model文件\n",
    "    builder.add_meta_graph_and_variables(sess, [\"serve\"])\n",
    "    # 第二步必需要有，它是给你的模型贴上一个标签，这样再次调用的时候就可以根据标签来找。我给它起的标签名是\"serve\"，你也可以起别的名字，不过你需要记住你起的名字是什么。\n",
    "    builder.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **1.2.2 模型的调用**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model_save/method_2/variables/variables\n",
      "[[0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[7 2 1 ... 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=tf.Graph()) as sess:\n",
    "    tf.saved_model.loader.load(sess, ['serve'], 'model_save/method_2')\n",
    "    y_pred=sess.graph.get_tensor_by_name(\"predict:0\")\n",
    "    x = sess.graph.get_tensor_by_name(\"x-input:0\")\n",
    "    y_= sess.run(y_pred, feed_dict={x: mnist_test.images})\n",
    "    print(mnist_test.labels)\n",
    "    print(y_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}