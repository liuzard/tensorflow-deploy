{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1、tensorflow 1.x 保存 MNIST 分类模型\n",
    "\n",
    "本文档在 tensorflow 1.x 的环境下训练一个mnist数据集分类模型，并保存训练之后的模型，作为后续部署的模型。\n",
    "由于本项目主要目的是说明模型的部署，所以模型和训练尽可能简单，理论上，任意模型按照本文档的方式保存，均可以进行后续的部署。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# 获取 mnist数据\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\",one_hot=True)\n",
    "mnist_train,mnist_validation,mnist_test=mnist.train,mnist.validation,mnist.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"x-input_1:0\", shape=(?, 784), dtype=float32)\n",
      "after 0 training steps, train_loss is 2.633871,validation accuracy is 0.367800\n",
      "after 1000 training steps, train_loss is 0.038347,validation accuracy is 0.970000\n",
      "after 2000 training steps, train_loss is 0.062370,validation accuracy is 0.976800\n",
      "after 3000 training steps, train_loss is 0.009625,validation accuracy is 0.978800\n",
      "after 4000 training steps, train_loss is 0.015266,validation accuracy is 0.980800\n",
      "after 5000 training steps, train_loss is 0.013237,validation accuracy is 0.982200\n",
      "after 6000 training steps, train_loss is 0.004261,validation accuracy is 0.982000\n",
      "after 7000 training steps, train_loss is 0.012332,validation accuracy is 0.981200\n",
      "after 8000 training steps, train_loss is 0.004618,validation accuracy is 0.982000\n",
      "after 9000 training steps, train_loss is 0.002695,validation accuracy is 0.982200\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'acc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-79f3ea12f57f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mval_acc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_feed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"after %d training steps, train_loss is %f,validation accuracy is %f\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mtest_acc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_feed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;31m# 保存模型\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'acc' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow import graph_util # 保存模型用到的方法\n",
    "\n",
    "# 模型参数\n",
    "input_dim=784\n",
    "hidden_dim=200\n",
    "output_dim=10\n",
    "learning_rate=0.5\n",
    "train_steps=10000\n",
    "batch_size=100\n",
    "\n",
    "# 模型的输入，在调用部署后的模型时需要用到，所以这里最好自己命名\n",
    "x = tf.placeholder(tf.float32, [None, input_dim], name='x-input')\n",
    "y_ = tf.placeholder(tf.float32, [None, output_dim], name='y-input')\n",
    "print(x)\n",
    "\n",
    "# 构建一个三层的全连接层网络，输入层、隐层和输出层分别为784,200,10\n",
    "weights_1 = tf.Variable(tf.random_normal(shape=[input_dim,hidden_dim],stddev=0.1),name='w1')\n",
    "bias_1 = tf.Variable(tf.constant(0.0, shape=[hidden_dim]),name=\"b1\")\n",
    "hidden=tf.matmul(x,weights_1)+bias_1\n",
    "hidden=tf.nn.relu(hidden)\n",
    "\n",
    "weights_2 = tf.Variable(tf.random_normal(shape=[hidden_dim,output_dim],stddev=0.1),name='w2')\n",
    "bias_2 = tf.Variable(tf.constant(0.0, shape=[output_dim]),name=\"b2\")\n",
    "y=tf.matmul(hidden,weights_2)+bias_2\n",
    "\n",
    "# 模型的预测输出，注意，因为我们部署之后希望拿到这个值，所以这里最好自己命名，后面部署之后的调用会用到\n",
    "soft_y=tf.nn.softmax(y,name=\"predict\") \n",
    "\n",
    "\n",
    "# 模型损失\n",
    "cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y, labels=tf.argmax(y_, 1))\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "# 预测精度\n",
    "correct_predict=tf.equal(tf.math.argmax(y,1),tf.math.argmax(y_,1))\n",
    "accuracy=tf.reduce_mean(tf.cast(correct_predict,tf.float32))\n",
    "\n",
    "#模型训练\n",
    "train_step=tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    validation_feed={x:mnist_validation.images,y_:mnist_validation.labels}\n",
    "    test_feed={x:mnist_test.images,y_:mnist_test.labels}\n",
    "    for i in range(train_steps):\n",
    "        train_samples,train_labels=mnist_train.next_batch(batch_size)\n",
    "        _,train_loss=sess.run([train_step,loss],feed_dict={x:train_samples,y_:train_labels})\n",
    "        if i%1000==0:\n",
    "            val_acc=sess.run(accuracy,feed_dict=validation_feed)\n",
    "            print(\"after %d training steps, loss of train set is %f,validation accuracy is %f\"%(i,train_loss,val_acc))\n",
    "    test_acc=sess.run(accuracy,feed_dict=test_feed)\n",
    "    print(\"test accuracy is %f\"%test_acc)\n",
    "    \n",
    "    # 保存模型\n",
    "    # 将权重和偏置等变量转换为常量，然后将计算图保存，可以大大减小保存后的模型\n",
    "    constant_graph = graph_util.convert_variables_to_constants(sess, sess.graph_def,output_node_names=[\"predict\"]) \n",
    "    model_save_path=\"model_save/mnist_classification.pb\"\n",
    "    with tf.gfile.FastGFile(model_save_path, mode='wb') as f:\n",
    "        f.write(constant_graph.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.17078504 0.04116438 0.0361588  ... 0.48151833 0.03096513 0.0252708 ]\n",
      " [0.14615275 0.17864934 0.07727    ... 0.32109454 0.05611867 0.0212088 ]\n",
      " [0.09626648 0.08087359 0.0399426  ... 0.20526746 0.05216448 0.09232967]\n",
      " ...\n",
      " [0.02843127 0.01009526 0.01514481 ... 0.6173448  0.05121985 0.01272882]\n",
      " [0.05012347 0.0671339  0.11344672 ... 0.46835944 0.01376875 0.01209813]\n",
      " [0.03849284 0.02034614 0.0193734  ... 0.52730286 0.27641186 0.02679564]]\n"
     ]
    }
   ],
   "source": [
    "# 在python 中调用保存好的模型进行预测\n",
    "from tensorflow.python.platform import gfile\n",
    "\n",
    "model_save_path=\"model_save/mnist_classification.pb\"\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # 读取保存的模型\n",
    "    with gfile.FastGFile(model_save_path, 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "    tf.import_graph_def(graph_def)\n",
    "    tf.global_variables_initializer().run()\n",
    "    g = tf.get_default_graph()\n",
    "    y_pred=g.get_tensor_by_name(\"predict:0\")\n",
    "    x = g.get_tensor_by_name(\"x-input:0\")\n",
    "    y_= sess.run(y_pred, feed_dict={x: mnist_test.images})\n",
    "    print(y_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
